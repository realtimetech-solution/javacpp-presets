// Targeted by JavaCPP version 1.5.6-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.tensorflowlite.global;

import org.bytedeco.tensorflowlite.*;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

public class tensorflowlite extends org.bytedeco.tensorflowlite.presets.tensorflowlite {
    static { Loader.load(); }

// Targeting ../StringIntMap.java


// Targeting ../TfLiteDelegatePtrVector.java


// Targeting ../StringVector.java


// Targeting ../SubgraphVector.java


// Targeting ../RegistrationNodePairVector.java


// Targeting ../RegistrationNodePair.java


// Targeting ../IntResourceBaseMap.java


// Parsed from tensorflow/lite/c/c_api_types.h

/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// This file declares types used by the pure C inference API defined in c_api.h,
// some of which are also used in the C++ and C kernel and interpreter APIs.

// #ifndef TENSORFLOW_LITE_C_C_API_TYPES_H_
// #define TENSORFLOW_LITE_C_C_API_TYPES_H_

// #include <stdint.h>

// #ifdef __cplusplus
// #endif

// Define TFL_CAPI_EXPORT macro to export a function properly with a shared
// library.
// #ifdef SWIG
// #define TFL_CAPI_EXPORT
// #else
// #if defined(_WIN32)
// #ifdef TFL_COMPILE_LIBRARY
// #define TFL_CAPI_EXPORT __declspec(dllexport)
// #else
// #define TFL_CAPI_EXPORT __declspec(dllimport)
// #endif  // TFL_COMPILE_LIBRARY
// #else
// #define TFL_CAPI_EXPORT __attribute__((visibility("default")))
// #endif  // _WIN32
// #endif  // SWIG

/** enum TfLiteStatus */
public static final int
  kTfLiteOk = 0,

  // Generally referring to an error in the runtime (i.e. interpreter)
  kTfLiteError = 1,

  // Generally referring to an error from a TfLiteDelegate itself.
  kTfLiteDelegateError = 2,

  // Generally referring to an error in applying a delegate due to
  // incompatibility between runtime and delegate, e.g., this error is returned
  // when trying to apply a TfLite delegate onto a model graph that's already
  // immutable.
  kTfLiteApplicationError = 3;

// Types supported by tensor
/** enum TfLiteType */
public static final int
  kTfLiteNoType = 0,
  kTfLiteFloat32 = 1,
  kTfLiteInt32 = 2,
  kTfLiteUInt8 = 3,
  kTfLiteInt64 = 4,
  kTfLiteString = 5,
  kTfLiteBool = 6,
  kTfLiteInt16 = 7,
  kTfLiteComplex64 = 8,
  kTfLiteInt8 = 9,
  kTfLiteFloat16 = 10,
  kTfLiteFloat64 = 11,
  kTfLiteComplex128 = 12,
  kTfLiteUInt64 = 13,
  kTfLiteResource = 14,
  kTfLiteVariant = 15,
  kTfLiteUInt32 = 16;
// Targeting ../TfLiteQuantizationParams.java



// #ifdef __cplusplus  // extern C
// #endif
// #endif  // TENSORFLOW_LITE_C_C_API_TYPES_H_


// Parsed from tensorflow/lite/c/common.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// This file defines common C types and APIs for implementing operations,
// delegates and other constructs in TensorFlow Lite. The actual operations and
// delegates can be defined using C++, but the interface between the interpreter
// and the operations are C.
//
// Summary of abstractions
// TF_LITE_ENSURE - Self-sufficient error checking
// TfLiteStatus - Status reporting
// TfLiteIntArray - stores tensor shapes (dims),
// TfLiteContext - allows an op to access the tensors
// TfLiteTensor - tensor (a multidimensional array)
// TfLiteNode - a single node or operation
// TfLiteRegistration - the implementation of a conceptual operation.
// TfLiteDelegate - allows delegation of nodes to alternative backends.
//
// Some abstractions in this file are created and managed by Interpreter.
//
// NOTE: The order of values in these structs are "semi-ABI stable". New values
// should be added only to the end of structs and never reordered.

// #ifndef TENSORFLOW_LITE_C_COMMON_H_
// #define TENSORFLOW_LITE_C_COMMON_H_

// #include <stdbool.h>
// #include <stddef.h>
// #include <stdint.h>

// #include "tensorflow/lite/c/c_api_types.h"  // IWYU pragma: export

// #ifdef __cplusplus
// #endif  // __cplusplus

// The list of external context types known to TF Lite. This list exists solely
// to avoid conflicts and to ensure ops can share the external contexts they
// need. Access to the external contexts is controlled by one of the
// corresponding support files.
/** enum TfLiteExternalContextType */
public static final int
  kTfLiteEigenContext = 0,       // include eigen_support.h to use.
  kTfLiteGemmLowpContext = 1,    // include gemm_support.h to use.
  kTfLiteEdgeTpuContext = 2,     // Placeholder for Edge TPU support.
  kTfLiteCpuBackendContext = 3,  // include cpu_backend_context.h to use.
  kTfLiteMaxExternalContexts = 4;

// Forward declare so dependent structs and methods can reference these types
// prior to the struct definitions.
// Targeting ../TfLiteExternalContext.java



public static final int kTfLiteOptionalTensor = (-1);
// Targeting ../TfLiteIntArray.java



// Given the size (number of elements) in a TfLiteIntArray, calculate its size
// in bytes.
public static native int TfLiteIntArrayGetSizeInBytes(int size);

// #ifndef TF_LITE_STATIC_MEMORY
// Create a array of a given `size` (uninitialized entries).
// This returns a pointer, that you must free using TfLiteIntArrayFree().
public static native TfLiteIntArray TfLiteIntArrayCreate(int size);
// #endif

// Check if two intarrays are equal. Returns 1 if they are equal, 0 otherwise.
public static native int TfLiteIntArrayEqual(@Const TfLiteIntArray a, @Const TfLiteIntArray b);

// Check if an intarray equals an array. Returns 1 if equals, 0 otherwise.
public static native int TfLiteIntArrayEqualsArray(@Const TfLiteIntArray a, int b_size,
                              @Const IntPointer b_data);
public static native int TfLiteIntArrayEqualsArray(@Const TfLiteIntArray a, int b_size,
                              @Const IntBuffer b_data);
public static native int TfLiteIntArrayEqualsArray(@Const TfLiteIntArray a, int b_size,
                              @Const int[] b_data);

// #ifndef TF_LITE_STATIC_MEMORY
// Create a copy of an array passed as `src`.
// You are expected to free memory with TfLiteIntArrayFree
public static native TfLiteIntArray TfLiteIntArrayCopy(@Const TfLiteIntArray src);

// Free memory of array `a`.
public static native void TfLiteIntArrayFree(TfLiteIntArray a);
// Targeting ../TfLiteFloatArray.java



// Given the size (number of elements) in a TfLiteFloatArray, calculate its size
// in bytes.
public static native int TfLiteFloatArrayGetSizeInBytes(int size);

// #ifndef TF_LITE_STATIC_MEMORY
// Create a array of a given `size` (uninitialized entries).
// This returns a pointer, that you must free using TfLiteFloatArrayFree().
public static native TfLiteFloatArray TfLiteFloatArrayCreate(int size);

// Free memory of array `a`.
public static native void TfLiteFloatArrayFree(TfLiteFloatArray a);
// #endif  // TF_LITE_STATIC_MEMORY

// Since we must not depend on any libraries, define a minimal subset of
// error macros while avoiding names that have pre-conceived meanings like
// assert and check.

// Try to make all reporting calls through TF_LITE_KERNEL_LOG rather than
// calling the context->ReportError function directly, so that message strings
// can be stripped out if the binary size needs to be severely optimized.
// #ifndef TF_LITE_STRIP_ERROR_STRINGS
// #define TF_LITE_KERNEL_LOG(context, ...)
//   do {
//     (context)->ReportError((context), __VA_ARGS__);
//   } while (false)

// #define TF_LITE_MAYBE_KERNEL_LOG(context, ...)
//   do {
//     if ((context) != nullptr) {
//       (context)->ReportError((context), __VA_ARGS__);
//     }
//   } while (false)
// #else  // TF_LITE_STRIP_ERROR_STRINGS
// #define TF_LITE_KERNEL_LOG(context, ...)
// #define TF_LITE_MAYBE_KERNEL_LOG(context, ...)
// #endif  // TF_LITE_STRIP_ERROR_STRINGS

// Check whether value is true, and if not return kTfLiteError from
// the current function (and report the error string msg).
// #define TF_LITE_ENSURE_MSG(context, value, msg)
//   do {
//     if (!(value)) {
//       TF_LITE_KERNEL_LOG((context), __FILE__ " " msg);
//       return kTfLiteError;
//     }
//   } while (0)

// Check whether the value `a` is true, and if not return kTfLiteError from
// the current function, while also reporting the location of the error.
// #define TF_LITE_ENSURE(context, a)
//   do {
//     if (!(a)) {
//       TF_LITE_KERNEL_LOG((context), "%s:%d %s was not true.", __FILE__,
//                          __LINE__, #a);
//       return kTfLiteError;
//     }
//   } while (0)

// #define TF_LITE_ENSURE_STATUS(a)
//   do {
//     const TfLiteStatus s = (a);
//     if (s != kTfLiteOk) {
//       return s;
//     }
//   } while (0)

// Check whether the value `a == b` is true, and if not return kTfLiteError from
// the current function, while also reporting the location of the error.
// `a` and `b` may be evaluated more than once, so no side effects or
// extremely expensive computations should be done.
// NOTE: Use TF_LITE_ENSURE_TYPES_EQ if comparing TfLiteTypes.
// #define TF_LITE_ENSURE_EQ(context, a, b)
//   do {
//     if ((a) != (b)) {
//       TF_LITE_KERNEL_LOG((context), "%s:%d %s != %s (%d != %d)", __FILE__,
//                          __LINE__, #a, #b, (a), (b));
//       return kTfLiteError;
//     }
//   } while (0)

// #define TF_LITE_ENSURE_TYPES_EQ(context, a, b)
//   do {
//     if ((a) != (b)) {
//       TF_LITE_KERNEL_LOG((context), "%s:%d %s != %s (%s != %s)", __FILE__,
//                          __LINE__, #a, #b, TfLiteTypeGetName(a),
//                          TfLiteTypeGetName(b));
//       return kTfLiteError;
//     }
//   } while (0)

// #define TF_LITE_ENSURE_NEAR(context, a, b, epsilon)
//   do {
//     auto delta = ((a) > (b)) ? ((a) - (b)) : ((b) - (a));
//     if (delta > epsilon) {
//       TF_LITE_KERNEL_LOG((context), "%s:%d %s not near %s (%f != %f)",
//                          __FILE__, __LINE__, #a, #b, static_cast<double>(a),
//                          static_cast<double>(b));
//       return kTfLiteError;
//     }
//   } while (0)

// #define TF_LITE_ENSURE_OK(context, status)
//   do {
//     const TfLiteStatus s = (status);
//     if ((s) != kTfLiteOk) {
//       return s;
//     }
//   } while (0)
// Targeting ../TfLiteComplex64.java


// Targeting ../TfLiteComplex128.java


// Targeting ../TfLiteFloat16.java



// Return the name of a given type, for error reporting purposes.
public static native @Cast("const char*") BytePointer TfLiteTypeGetName(@Cast("TfLiteType") int type);

// SupportedQuantizationTypes.
/** enum TfLiteQuantizationType */
public static final int
  // No quantization.
  kTfLiteNoQuantization = 0,
  // Affine quantization (with support for per-channel quantization).
  // Corresponds to TfLiteAffineQuantization.
  kTfLiteAffineQuantization = 1;
// Targeting ../TfLiteQuantization.java


// Targeting ../TfLiteAffineQuantization.java


// Targeting ../TfLitePtrUnion.java



// Memory allocation strategies.
//  * kTfLiteMmapRo: Read-only memory-mapped data, or data externally allocated.
//  * kTfLiteArenaRw: Arena allocated with no guarantees about persistence,
//        and available during eval.
//  * kTfLiteArenaRwPersistent: Arena allocated but persistent across eval, and
//        only available during eval.
//  * kTfLiteDynamic: Allocated during eval, or for string tensors.
//  * kTfLitePersistentRo: Allocated and populated during prepare. This is
//        useful for tensors that can be computed during prepare and treated
//        as constant inputs for downstream ops (also in prepare).
//  * kTfLiteCustom: Custom memory allocation provided by the user. See
//        TfLiteCustomAllocation below.
/** enum TfLiteAllocationType */
public static final int
  kTfLiteMemNone = 0,
  kTfLiteMmapRo = 1,
  kTfLiteArenaRw = 2,
  kTfLiteArenaRwPersistent = 3,
  kTfLiteDynamic = 4,
  kTfLitePersistentRo = 5,
  kTfLiteCustom = 6;

// The delegates should use zero or positive integers to represent handles.
// -1 is reserved from unallocated status.
/** enum  */
public static final int
  kTfLiteNullBufferHandle = -1;

// Storage format of each dimension in a sparse tensor.
/** enum TfLiteDimensionType */
public static final int
  kTfLiteDimDense = 0,
  kTfLiteDimSparseCSR = 1;
// Targeting ../TfLiteDimensionMetadata.java


// Targeting ../TfLiteSparsity.java


// Targeting ../TfLiteCustomAllocation.java



// The flags used in `Interpreter::SetCustomAllocationForTensor`.
// Note that this is a bitmask, so the values should be 1, 2, 4, 8, ...etc.
/** enum TfLiteCustomAllocationFlags */
public static final int
  kTfLiteCustomAllocationFlagsNone = 0,
  // Skips checking whether allocation.data points to an aligned buffer as
  // expected by the TFLite runtime.
  // NOTE: Setting this flag can cause crashes when calling Invoke().
  // Use with caution.
  kTfLiteCustomAllocationFlagsSkipAlignCheck = 1;
// Targeting ../TfLiteTensor.java


// Targeting ../TfLiteNode.java


// #else   // defined(TF_LITE_STATIC_MEMORY)?
// NOTE: This flag is opt-in only at compile time.
//
// Specific reduced TfLiteTensor struct for TF Micro runtime. This struct
// contains only the minimum fields required to initialize and prepare a micro
// inference graph. The fields in this struct have been ordered from
// largest-to-smallest for optimal struct sizeof.
//
// This struct does not use:
// - allocation
// - buffer_handle
// - data_is_stale
// - delegate
// - dims_signature
// - name
// - sparsity

// Specific reduced TfLiteNode struct for TF Micro runtime. This struct contains
// only the minimum fields required to represent a node.
//
// This struct does not use:
// - delegate
// - intermediates
// - temporaries
// Targeting ../TfLiteEvalTensor.java



// #ifndef TF_LITE_STATIC_MEMORY
// Free data memory of tensor `t`.
public static native void TfLiteTensorDataFree(TfLiteTensor t);

// Free quantization data.
public static native void TfLiteQuantizationFree(TfLiteQuantization quantization);

// Free sparsity parameters.
public static native void TfLiteSparsityFree(TfLiteSparsity sparsity);

// Free memory of tensor `t`.
public static native void TfLiteTensorFree(TfLiteTensor t);

// Set all of a tensor's fields (and free any previously allocated data).
public static native void TfLiteTensorReset(@Cast("TfLiteType") int type, @Cast("const char*") BytePointer name, TfLiteIntArray dims,
                       @ByVal TfLiteQuantizationParams quantization, @Cast("char*") BytePointer buffer,
                       @Cast("size_t") long size, @Cast("TfLiteAllocationType") int allocation_type,
                       @Const Pointer allocation, @Cast("bool") boolean is_variable,
                       TfLiteTensor tensor);
public static native void TfLiteTensorReset(@Cast("TfLiteType") int type, String name, TfLiteIntArray dims,
                       @ByVal TfLiteQuantizationParams quantization, @Cast("char*") ByteBuffer buffer,
                       @Cast("size_t") long size, @Cast("TfLiteAllocationType") int allocation_type,
                       @Const Pointer allocation, @Cast("bool") boolean is_variable,
                       TfLiteTensor tensor);
public static native void TfLiteTensorReset(@Cast("TfLiteType") int type, @Cast("const char*") BytePointer name, TfLiteIntArray dims,
                       @ByVal TfLiteQuantizationParams quantization, @Cast("char*") byte[] buffer,
                       @Cast("size_t") long size, @Cast("TfLiteAllocationType") int allocation_type,
                       @Const Pointer allocation, @Cast("bool") boolean is_variable,
                       TfLiteTensor tensor);
public static native void TfLiteTensorReset(@Cast("TfLiteType") int type, String name, TfLiteIntArray dims,
                       @ByVal TfLiteQuantizationParams quantization, @Cast("char*") BytePointer buffer,
                       @Cast("size_t") long size, @Cast("TfLiteAllocationType") int allocation_type,
                       @Const Pointer allocation, @Cast("bool") boolean is_variable,
                       TfLiteTensor tensor);
public static native void TfLiteTensorReset(@Cast("TfLiteType") int type, @Cast("const char*") BytePointer name, TfLiteIntArray dims,
                       @ByVal TfLiteQuantizationParams quantization, @Cast("char*") ByteBuffer buffer,
                       @Cast("size_t") long size, @Cast("TfLiteAllocationType") int allocation_type,
                       @Const Pointer allocation, @Cast("bool") boolean is_variable,
                       TfLiteTensor tensor);
public static native void TfLiteTensorReset(@Cast("TfLiteType") int type, String name, TfLiteIntArray dims,
                       @ByVal TfLiteQuantizationParams quantization, @Cast("char*") byte[] buffer,
                       @Cast("size_t") long size, @Cast("TfLiteAllocationType") int allocation_type,
                       @Const Pointer allocation, @Cast("bool") boolean is_variable,
                       TfLiteTensor tensor);

// Resize the allocated data of a (dynamic) tensor. Tensors with allocation
// types other than kTfLiteDynamic will be ignored.
public static native void TfLiteTensorRealloc(@Cast("size_t") long num_bytes, TfLiteTensor tensor);
// Targeting ../TfLiteDelegateParams.java


// Targeting ../TfLiteContext.java


// Targeting ../TfLiteRegistration.java



// The flags used in `TfLiteDelegate`. Note that this is a bitmask, so the
// values should be 1, 2, 4, 8, ...etc.
/** enum TfLiteDelegateFlags */
public static final int
  kTfLiteDelegateFlagsNone = 0,
  // The flag is set if the delegate can handle dynamic sized tensors.
  // For example, the output shape of a `Resize` op with non-constant shape
  // can only be inferred when the op is invoked.
  // In this case, the Delegate is responsible for calling
  // `SetTensorToDynamic` to mark the tensor as a dynamic tensor, and calling
  // `ResizeTensor` when invoking the op.
  //
  // If the delegate isn't capable to handle dynamic tensors, this flag need
  // to be set to false.
  kTfLiteDelegateFlagsAllowDynamicTensors = 1,

  // This flag can be used by delegates (that allow dynamic tensors) to ensure
  // applicable tensor shapes are automatically propagated in the case of tensor
  // resizing.
  // This means that non-dynamic (allocation_type != kTfLiteDynamic) I/O tensors
  // of a delegate kernel will have correct shapes before its Prepare() method
  // is called. The runtime leverages TFLite builtin ops in the original
  // execution plan to propagate shapes.
  //
  // A few points to note:
  // 1. This requires kTfLiteDelegateFlagsAllowDynamicTensors. If that flag is
  // false, this one is redundant since the delegate kernels are re-initialized
  // every time tensors are resized.
  // 2. Enabling this flag adds some overhead to AllocateTensors(), since extra
  // work is required to prepare the original execution plan.
  // 3. This flag requires that the original execution plan only have ops with
  // valid registrations (and not 'dummy' custom ops like with Flex).
  // WARNING: This feature is experimental and subject to change.
  kTfLiteDelegateFlagsRequirePropagatedShapes = 2;
// Targeting ../TfLiteDelegate.java



// Build a 'null' delegate, with all the fields properly set to their default
// values.
public static native @ByVal TfLiteDelegate TfLiteDelegateCreate();

// #ifdef __cplusplus  // extern "C"
// #endif  // __cplusplus
// #endif  // TENSORFLOW_LITE_C_COMMON_H_


// Parsed from tensorflow/lite/core/api/error_reporter.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_CORE_API_ERROR_REPORTER_H_
// #define TENSORFLOW_LITE_CORE_API_ERROR_REPORTER_H_

// #include <cstdarg>
// Targeting ../ErrorReporter.java



  // namespace tflite

// You should not make bare calls to the error reporter, instead use the
// TF_LITE_REPORT_ERROR macro, since this allows message strings to be
// stripped when the binary size has to be optimized. If you are looking to
// reduce binary size, define TF_LITE_STRIP_ERROR_STRINGS when compiling and
// every call will be stubbed out, taking no memory.
// #ifndef TF_LITE_STRIP_ERROR_STRINGS
// #define TF_LITE_REPORT_ERROR(reporter, ...)
//   do {
//     static_cast<tflite::ErrorReporter*>(reporter)->Report(__VA_ARGS__);
//   } while (false)
// #else  // TF_LITE_STRIP_ERROR_STRINGS
// #define TF_LITE_REPORT_ERROR(reporter, ...)
// #endif  // TF_LITE_STRIP_ERROR_STRINGS

// #endif  // TENSORFLOW_LITE_CORE_API_ERROR_REPORTER_H_


// Parsed from tensorflow/lite/core/api/op_resolver.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_CORE_API_OP_RESOLVER_H_
// #define TENSORFLOW_LITE_CORE_API_OP_RESOLVER_H_

// #include <memory>
// #include <vector>

// #include "tensorflow/lite/c/common.h"
// #include "tensorflow/lite/core/api/error_reporter.h"
// #include "tensorflow/lite/schema/schema_generated.h"
// Targeting ../OpResolver.java



// Handles the logic for converting between an OperatorCode structure extracted
// from a flatbuffer and information about a registered operator
// implementation.
@Namespace("tflite") public static native @Cast("TfLiteStatus") int GetRegistrationFromOpCode(@Cast("const tflite::OperatorCode*") Pointer opcode,
                                       @Const @ByRef OpResolver op_resolver,
                                       ErrorReporter error_reporter,
                                       @Cast("const TfLiteRegistration**") PointerPointer registration);
@Namespace("tflite") public static native @Cast("TfLiteStatus") int GetRegistrationFromOpCode(@Cast("const tflite::OperatorCode*") Pointer opcode,
                                       @Const @ByRef OpResolver op_resolver,
                                       ErrorReporter error_reporter,
                                       @Const @ByPtrPtr TfLiteRegistration registration);

  // namespace tflite

// #endif  // TENSORFLOW_LITE_CORE_API_OP_RESOLVER_H_


// Parsed from tensorflow/lite/core/api/profiler.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_CORE_API_PROFILER_H_
// #define TENSORFLOW_LITE_CORE_API_PROFILER_H_

// #include <cstdint>
// Targeting ../Profiler.java


// Targeting ../ScopedProfile.java


// Targeting ../ScopedOperatorProfile.java


// Targeting ../ScopedDelegateOperatorProfile.java


// Targeting ../ScopedRuntimeInstrumentationProfile.java



  // namespace tflite

// #define TFLITE_VARNAME_UNIQ_IMPL(name, ctr) name##ctr
// #define TFLITE_VARNAME_UNIQ(name, ctr) TFLITE_VARNAME_UNIQ_IMPL(name, ctr)

// #define TFLITE_SCOPED_TAGGED_DEFAULT_PROFILE(profiler, tag)
//   tflite::ScopedProfile TFLITE_VARNAME_UNIQ(_profile_, __COUNTER__)(
//       (profiler), (tag))

// #define TFLITE_SCOPED_TAGGED_OPERATOR_PROFILE(profiler, tag, node_index)
//   tflite::ScopedOperatorProfile TFLITE_VARNAME_UNIQ(_profile_, __COUNTER__)(
//       (profiler), (tag), (node_index))

// #define TFLITE_SCOPED_DELEGATE_OPERATOR_PROFILE(profiler, tag, node_index)
//   tflite::ScopedDelegateOperatorProfile TFLITE_VARNAME_UNIQ(
//       _profile_, __COUNTER__)((profiler), (tag), (node_index))

// #define TFLITE_ADD_RUNTIME_INSTRUMENTATION_EVENT(
//     profiler, tag, event_metadata1, event_metadata2)
//   do {
//     if (profiler) {
//       const auto handle = profiler->BeginEvent(
//           tag, Profiler::EventType::GENERAL_RUNTIME_INSTRUMENTATION_EVENT,
//           event_metadata1, event_metadata2);
//       profiler->EndEvent(handle);
//     }
//   } while (false);

// #endif  // TENSORFLOW_LITE_CORE_API_PROFILER_H_


// Parsed from tensorflow/lite/core/api/verifier.h

/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
/** \file
/** Abstract interface for verifying a model. */
// #ifndef TENSORFLOW_LITE_CORE_API_VERIFIER_H_
// #define TENSORFLOW_LITE_CORE_API_VERIFIER_H_

// #include "tensorflow/lite/core/api/error_reporter.h"
// Targeting ../TfLiteVerifier.java



  // namespace tflite

// #endif  // TENSORFLOW_LITE_CORE_API_VERIFIER_H_


// Parsed from tensorflow/lite/experimental/resource/resource_base.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_EXPERIMENTAL_RESOURCE_RESOURCE_BASE_H_
// #define TENSORFLOW_LITE_EXPERIMENTAL_RESOURCE_RESOURCE_BASE_H_

// #include <cstdint>
// #include <memory>
// #include <unordered_map>
// Targeting ../ResourceBase.java



/** WARNING: Experimental interface, subject to change. */

  // namespace resource
  // namespace tflite

// #endif  // TENSORFLOW_LITE_EXPERIMENTAL_RESOURCE_RESOURCE_BASE_H_


// Parsed from tensorflow/lite/allocation.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
/** \file
/** Memory management for TF Lite. */
// #ifndef TENSORFLOW_LITE_ALLOCATION_H_
// #define TENSORFLOW_LITE_ALLOCATION_H_

// #include <stddef.h>

// #include <cstdio>
// #include <cstdlib>
// #include <memory>

// #include "tensorflow/lite/core/api/error_reporter.h"
// Targeting ../Allocation.java


// Targeting ../MMAPAllocation.java


// Targeting ../FileCopyAllocation.java


// Targeting ../MemoryAllocation.java



  // namespace tflite

// #endif  // TENSORFLOW_LITE_ALLOCATION_H_


// Parsed from tensorflow/lite/stderr_reporter.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_STDERR_REPORTER_H_
// #define TENSORFLOW_LITE_STDERR_REPORTER_H_

// #include <cstdarg>

// #include "tensorflow/lite/c/common.h"
// #include "tensorflow/lite/core/api/error_reporter.h"
// Targeting ../StderrReporter.java



// Return the default error reporter (output to stderr).
@Namespace("tflite") public static native ErrorReporter DefaultErrorReporter();

  // namespace tflite

// #endif  // TENSORFLOW_LITE_STDERR_REPORTER_H_


// Parsed from tensorflow/lite/memory_planner.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_MEMORY_PLANNER_H_
// #define TENSORFLOW_LITE_MEMORY_PLANNER_H_

// #include "tensorflow/lite/c/common.h"
// Targeting ../MemoryPlanner.java



  // namespace tflite

// #endif  // TENSORFLOW_LITE_MEMORY_PLANNER_H_


// Parsed from tensorflow/lite/util.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

// This file provides general C++ utility functions in TFLite.
// For example: Converting between `TfLiteIntArray`, `std::vector` and
// Flatbuffer vectors. These functions can't live in `context.h` since it's pure
// C.

// #ifndef TENSORFLOW_LITE_UTIL_H_
// #define TENSORFLOW_LITE_UTIL_H_

// #include <stddef.h>

// #include <initializer_list>
// #include <memory>
// #include <string>
// #include <vector>

// #include "tensorflow/lite/c/common.h"

// Memory allocation parameter used by ArenaPlanner.
// Clients (such as delegates) might look at this to ensure interop between
// TFLite memory & hardware buffers.
// NOTE: This only holds for tensors allocated on the arena.
@Namespace("tflite") @MemberGetter public static native int kDefaultTensorAlignment();

// The prefix of Flex op custom code.
// This will be matched agains the `custom_code` field in `OperatorCode`
// Flatbuffer Table.
// WARNING: This is an experimental API and subject to change.
@Namespace("tflite") @MemberGetter public static native @Cast("const char") byte kFlexCustomCodePrefix(int i);
@Namespace("tflite") @MemberGetter public static native @Cast("const char*") BytePointer kFlexCustomCodePrefix();

// Checks whether the prefix of the custom name indicates the operation is an
// Flex operation.
@Namespace("tflite") public static native @Cast("bool") boolean IsFlexOp(@Cast("const char*") BytePointer custom_name);
@Namespace("tflite") public static native @Cast("bool") boolean IsFlexOp(String custom_name);

// Converts a `std::vector` to a `TfLiteIntArray`. The caller takes ownership
// of the returned pointer.
@Namespace("tflite") public static native TfLiteIntArray ConvertVectorToTfLiteIntArray(@StdVector IntPointer input);
@Namespace("tflite") public static native TfLiteIntArray ConvertVectorToTfLiteIntArray(@StdVector IntBuffer input);
@Namespace("tflite") public static native TfLiteIntArray ConvertVectorToTfLiteIntArray(@StdVector int[] input);

// Converts an array (of the given size) to a `TfLiteIntArray`. The caller
// takes ownership of the returned pointer, and must make sure 'dims' has at
// least 'rank' elements.
@Namespace("tflite") public static native TfLiteIntArray ConvertArrayToTfLiteIntArray(int rank, @Const IntPointer dims);
@Namespace("tflite") public static native TfLiteIntArray ConvertArrayToTfLiteIntArray(int rank, @Const IntBuffer dims);
@Namespace("tflite") public static native TfLiteIntArray ConvertArrayToTfLiteIntArray(int rank, @Const int[] dims);

// Checks whether a `TfLiteIntArray` and an int array have matching elements.
// The caller must guarantee that 'b' has at least 'b_size' elements.
@Namespace("tflite") public static native @Cast("bool") boolean EqualArrayAndTfLiteIntArray(@Const TfLiteIntArray a, int b_size,
                                 @Const IntPointer b);
@Namespace("tflite") public static native @Cast("bool") boolean EqualArrayAndTfLiteIntArray(@Const TfLiteIntArray a, int b_size,
                                 @Const IntBuffer b);
@Namespace("tflite") public static native @Cast("bool") boolean EqualArrayAndTfLiteIntArray(@Const TfLiteIntArray a, int b_size,
                                 @Const int[] b);
// Targeting ../TfLiteIntArrayDeleter.java



// Helper for Building TfLiteIntArray that is wrapped in a unique_ptr,
// So that it is automatically freed when it goes out of the scope.
@Namespace("tflite") public static native @UniquePtr("TfLiteIntArray,tflite::TfLiteIntArrayDeleter") @ByVal TfLiteIntArray BuildTfLiteIntArray(
    @StdVector IntPointer data);
@Namespace("tflite") public static native @UniquePtr("TfLiteIntArray,tflite::TfLiteIntArrayDeleter") @ByVal TfLiteIntArray BuildTfLiteIntArray(
    @StdVector IntBuffer data);
@Namespace("tflite") public static native @UniquePtr("TfLiteIntArray,tflite::TfLiteIntArrayDeleter") @ByVal TfLiteIntArray BuildTfLiteIntArray(
    @StdVector int[] data);

// Populates the size in bytes of a type into `bytes`. Returns kTfLiteOk for
// valid types, and kTfLiteError otherwise.
@Namespace("tflite") public static native @Cast("TfLiteStatus") int GetSizeOfType(TfLiteContext context, @Cast("const TfLiteType") int type,
                           @Cast("size_t*") SizeTPointer bytes);

// Creates a stub TfLiteRegistration instance with the provided
// `custom_op_name`. The op will fail if invoked, and is useful as a
// placeholder to defer op resolution.
// Note that `custom_op_name` must remain valid for the returned op's lifetime..
@Namespace("tflite") public static native @ByVal TfLiteRegistration CreateUnresolvedCustomOp(@Cast("const char*") BytePointer custom_op_name);
@Namespace("tflite") public static native @ByVal TfLiteRegistration CreateUnresolvedCustomOp(String custom_op_name);

// Checks whether the provided op is an unresolved custom op.
@Namespace("tflite") public static native @Cast("bool") boolean IsUnresolvedCustomOp(@Const @ByRef TfLiteRegistration registration);

// Returns a descriptive name with the given op TfLiteRegistration.
@Namespace("tflite") public static native @StdString String GetOpNameByRegistration(@Const @ByRef TfLiteRegistration registration);

// The prefix of a validation subgraph name.
// WARNING: This is an experimental API and subject to change.
@Namespace("tflite") @MemberGetter public static native @Cast("const char") byte kValidationSubgraphNamePrefix(int i);
@Namespace("tflite") @MemberGetter public static native @Cast("const char*") BytePointer kValidationSubgraphNamePrefix();

// Checks whether the prefix of the subgraph name indicates the subgraph is a
// validation subgraph.
@Namespace("tflite") public static native @Cast("bool") boolean IsValidationSubgraph(@Cast("const char*") BytePointer name);
@Namespace("tflite") public static native @Cast("bool") boolean IsValidationSubgraph(String name);
  // namespace tflite

// #endif  // TENSORFLOW_LITE_UTIL_H_


// Parsed from tensorflow/lite/core/macros.h

/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// This provides utility macros and functions that are inherently platform
// specific.
// #ifndef TENSORFLOW_LITE_CORE_MACROS_H_
// #define TENSORFLOW_LITE_CORE_MACROS_H_

// #ifdef __has_builtin
// #define TFLITE_HAS_BUILTIN(x) __has_builtin(x)
// #else
// #define TFLITE_HAS_BUILTIN(x) 0
// #endif

// #if (!defined(__NVCC__)) && (TFLITE_HAS_BUILTIN(__builtin_expect) ||
//                              (defined(__GNUC__) && __GNUC__ >= 3))
// #define TFLITE_EXPECT_FALSE(cond) __builtin_expect(cond, false)
// #define TFLITE_EXPECT_TRUE(cond) __builtin_expect(!!(cond), true)
// #else
// #define TFLITE_EXPECT_FALSE(cond) (cond)
// #define TFLITE_EXPECT_TRUE(cond) (cond)
// #endif

// Normally we'd use ABSL_HAVE_ATTRIBUTE_WEAK and ABSL_ATTRIBUTE_WEAK, but
// we avoid the absl dependency for binary size reasons.
// #ifdef __has_attribute
// #define TFLITE_HAS_ATTRIBUTE(x) __has_attribute(x)
// #else
// #define TFLITE_HAS_ATTRIBUTE(x) 0
// #endif

// #if (TFLITE_HAS_ATTRIBUTE(weak) ||
//      (defined(__GNUC__) && !defined(__clang__))) &&
//     !(defined(__llvm__) && defined(_WIN32)) && !defined(__MINGW32__)
// #undef TFLITE_ATTRIBUTE_WEAK
// #define TFLITE_ATTRIBUTE_WEAK __attribute__((weak))
public static final int TFLITE_HAS_ATTRIBUTE_WEAK = 1;
// #else
// #define TFLITE_ATTRIBUTE_WEAK
// #endif

// #endif  // TENSORFLOW_LITE_CORE_MACROS_H_


// Parsed from tensorflow/lite/core/subgraph.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_CORE_SUBGRAPH_H_
// #define TENSORFLOW_LITE_CORE_SUBGRAPH_H_

// #include <stdarg.h>
// #include <stddef.h>

// #include <cstdint>
// #include <cstdlib>
// #include <map>
// #include <memory>
// #include <utility>
// #include <vector>

// #include "tensorflow/lite/allocation.h"
// #include "tensorflow/lite/c/common.h"
// #include "tensorflow/lite/core/api/error_reporter.h"
// #include "tensorflow/lite/core/api/profiler.h"
// #include "tensorflow/lite/core/macros.h"
// #include "tensorflow/lite/experimental/resource/resource_base.h"
// #include "tensorflow/lite/memory_planner.h"
// #include "tensorflow/lite/util.h"
// Targeting ../TestDelegate.java

  // Class for friend declarations.
  // namespace test_utils

// Targeting ../Subgraph.java



  // namespace tflite
// #endif  // TENSORFLOW_LITE_CORE_SUBGRAPH_H_


// Parsed from tensorflow/lite/external_cpu_backend_context.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_EXTERNAL_CPU_BACKEND_CONTEXT_H_
// #define TENSORFLOW_LITE_EXTERNAL_CPU_BACKEND_CONTEXT_H_

// #include <memory>
// #include <utility>

// #include "tensorflow/lite/c/common.h"
// Targeting ../TfLiteInternalBackendContext.java


// Targeting ../ExternalCpuBackendContext.java



  // namespace tflite

// #endif  // TENSORFLOW_LITE_EXTERNAL_CPU_BACKEND_CONTEXT_H_


// Parsed from tensorflow/lite/portable_type_to_tflitetype.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_PORTABLE_TYPE_TO_TFLITETYPE_H_
// #define TENSORFLOW_LITE_PORTABLE_TYPE_TO_TFLITETYPE_H_

// Most of the definitions have been moved to this subheader so that Micro
// can include it without relying on <string> and <complex>, which isn't
// available on all platforms.

// Arduino build defines abs as a macro here. That is invalid C++, and breaks
// libc++'s <complex> header, undefine it.
// #ifdef abs
// #undef abs
// #endif

// #include <stdint.h>

// #include "tensorflow/lite/c/common.h"

// Map statically from a C++ type to a TfLiteType. Used in interpreter for
// safe casts.
// Example:
//  typeToTfLiteType<bool>() -> kTfLiteBool

// Map from TfLiteType to the corresponding C++ type.
// Example:
//   TfLiteTypeToType<kTfLiteBool>::Type -> bool  // Specializations below

// Template specialization for both typeToTfLiteType and TfLiteTypeToType.
// #define MATCH_TYPE_AND_TFLITE_TYPE(CPP_TYPE, TFLITE_TYPE_ENUM)
//   template <>
//   constexpr TfLiteType typeToTfLiteType<CPP_TYPE>() {
//     return TFLITE_TYPE_ENUM;
//   }
//   template <>
//   struct TfLiteTypeToType<TFLITE_TYPE_ENUM> {
//     using Type = CPP_TYPE;
//   }

// No string mapping is included here, since the TF Lite packed representation
// doesn't correspond to a C++ type well.

// Targeting ../TfLiteTypeToType.java













  // namespace tflite
// #endif  // TENSORFLOW_LITE_PORTABLE_TYPE_TO_TFLITETYPE_H_


// Parsed from tensorflow/lite/type_to_tflitetype.h

/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_TYPE_TO_TFLITETYPE_H_
// #define TENSORFLOW_LITE_TYPE_TO_TFLITETYPE_H_

// #include <complex>
// #include <string>

// #include "tensorflow/lite/c/common.h"

// Most of the definitions have been moved to this subheader so that Micro
// can include it without relying on <string> and <complex>, which isn't
// available on all platforms.
// #include "tensorflow/lite/portable_type_to_tflitetype.h"

// TODO(b/163167649): This string conversion means that only the first entry
// in a string tensor will be returned as a std::string, so it's deprecated.





  // namespace tflite
// #endif  // TENSORFLOW_LITE_TYPE_TO_TFLITETYPE_H_


// Parsed from tensorflow/lite/string_type.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// Abstract string. We don't want even absl at this level.
// #ifndef TENSORFLOW_LITE_STRING_TYPE_H_
// #define TENSORFLOW_LITE_STRING_TYPE_H_

// #include <string>

  // namespace tflite

// #endif  // TENSORFLOW_LITE_STRING_TYPE_H_


// Parsed from tensorflow/lite/mutable_op_resolver.h

/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_MUTABLE_OP_RESOLVER_H_
// #define TENSORFLOW_LITE_MUTABLE_OP_RESOLVER_H_

// #include <stddef.h>

// #include <string>
// #include <unordered_map>
// #include <utility>

// #include "tensorflow/lite/c/common.h"
// #include "tensorflow/lite/core/api/op_resolver.h"
// #include "tensorflow/lite/schema/schema_generated.h"
// #include "tensorflow/lite/util.h"
// Targeting ../ValueHasher.java



// Targeting ../MutableOpResolver.java



  // namespace tflite

// #endif  // TENSORFLOW_LITE_MUTABLE_OP_RESOLVER_H_


// Parsed from tensorflow/lite/interpreter.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
/** \file
/** Main abstraction controlling the tflite interpreter.
/** See context.h for the API for defining operations (TfLiteRegistration). */
// #ifndef TENSORFLOW_LITE_INTERPRETER_H_
// #define TENSORFLOW_LITE_INTERPRETER_H_

// #include <stddef.h>
// #include <stdint.h>

// #include <complex>
// #include <cstdio>
// #include <cstdlib>
// #include <functional>
// #include <map>
// #include <memory>
// #include <string>
// #include <utility>
// #include <vector>

// #include "tensorflow/lite/allocation.h"
// #include "tensorflow/lite/c/common.h"  // IWYU pragma: export
// #include "tensorflow/lite/core/api/error_reporter.h"
// #include "tensorflow/lite/core/api/profiler.h"
// #include "tensorflow/lite/core/subgraph.h"
// #include "tensorflow/lite/experimental/resource/resource_base.h"
// #include "tensorflow/lite/external_cpu_backend_context.h"
// #include "tensorflow/lite/memory_planner.h"
// #include "tensorflow/lite/portable_type_to_tflitetype.h"
// #include "tensorflow/lite/stderr_reporter.h"
// #include "tensorflow/lite/string_type.h"
// #include "tensorflow/lite/type_to_tflitetype.h"
// Targeting ../InterpreterTest.java


// Targeting ../InterpreterUtils.java

  // Class for friend declarations.  // Class for friend declarations.
  // namespace test_utils

// Targeting ../Interpreter.java



  // namespace tflite
// #endif  // TENSORFLOW_LITE_INTERPRETER_H_


// Parsed from tensorflow/lite/model_builder.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
/** \file
/** Deserialization infrastructure for tflite. Provides functionality
/** to go from a serialized tflite model in flatbuffer format to an
/** in-memory representation of the model.
/** */
// #ifndef TENSORFLOW_LITE_MODEL_BUILDER_H_
// #define TENSORFLOW_LITE_MODEL_BUILDER_H_

// #include <stddef.h>

// #include <memory>
// #include <string>

// #include "tensorflow/lite/allocation.h"
// #include "tensorflow/lite/c/common.h"
// #include "tensorflow/lite/core/api/error_reporter.h"
// #include "tensorflow/lite/core/api/op_resolver.h"
// #include "tensorflow/lite/core/api/verifier.h"
// #include "tensorflow/lite/mutable_op_resolver.h"
// #include "tensorflow/lite/schema/schema_generated.h"
// #include "tensorflow/lite/stderr_reporter.h"
// #include "tensorflow/lite/string_type.h"
// Targeting ../FlatBufferModel.java



  // namespace tflite

// #endif  // TENSORFLOW_LITE_MODEL_BUILDER_H_


// Parsed from tensorflow/lite/interpreter_builder.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
/** \file
/** Provides functionality to construct an interpreter for a model.
/** */
// #ifndef TENSORFLOW_LITE_INTERPRETER_BUILDER_H_
// #define TENSORFLOW_LITE_INTERPRETER_BUILDER_H_

// #include <memory>
// #include <vector>

// #include "flatbuffers/flatbuffers.h"  // from @flatbuffers
// #include "tensorflow/lite/allocation.h"
// #include "tensorflow/lite/c/common.h"
// #include "tensorflow/lite/core/api/error_reporter.h"
// #include "tensorflow/lite/core/api/op_resolver.h"
// #include "tensorflow/lite/core/subgraph.h"
// #include "tensorflow/lite/interpreter.h"
// #include "tensorflow/lite/model_builder.h"
// #include "tensorflow/lite/mutable_op_resolver.h"
// #include "tensorflow/lite/schema/schema_generated.h"
// #include "tensorflow/lite/stderr_reporter.h"
// Targeting ../InterpreterBuilder.java



  // namespace tflite

// #endif  // TENSORFLOW_LITE_INTERPRETER_BUILDER_H_


// Parsed from tensorflow/lite/model.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
/** \file
/** Defines tflite::Interpreter and tflite::InterpreterBuilder.
/** */
// #ifndef TENSORFLOW_LITE_MODEL_H_
// #define TENSORFLOW_LITE_MODEL_H_

// #include "tensorflow/lite/interpreter_builder.h"
// #include "tensorflow/lite/model_builder.h"

// TODO(b/168725050): Address the issue of proxy header in this file.

// #endif  // TENSORFLOW_LITE_MODEL_H_


// Parsed from tensorflow/lite/kernels/register.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// #ifndef TENSORFLOW_LITE_KERNELS_REGISTER_H_
// #define TENSORFLOW_LITE_KERNELS_REGISTER_H_

// #include "tensorflow/lite/model.h"  // Legacy.
// #include "tensorflow/lite/mutable_op_resolver.h"
// Targeting ../BuiltinOpResolver.java


// Targeting ../BuiltinOpResolverWithoutDefaultDelegates.java



  // namespace builtin
  // namespace ops
  // namespace tflite

// #endif  // TENSORFLOW_LITE_KERNELS_REGISTER_H_


// Parsed from tensorflow/lite/optional_debug_tools.h

/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
/** \file
/** Optional debugging functionality.
/** For small sized binaries, these are not needed. */
// #ifndef TENSORFLOW_LITE_OPTIONAL_DEBUG_TOOLS_H_
// #define TENSORFLOW_LITE_OPTIONAL_DEBUG_TOOLS_H_

// #include "tensorflow/lite/interpreter.h"

// Prints a dump of what tensors and what nodes are in the interpreter.
@Namespace("tflite") public static native void PrintInterpreterState(Interpreter interpreter);

  // namespace tflite

// #endif  // TENSORFLOW_LITE_OPTIONAL_DEBUG_TOOLS_H_


}
